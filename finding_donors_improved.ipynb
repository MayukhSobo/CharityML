{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement of previous donor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have choosen 3 models on the data that we have gathered.\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Gradient Boosting\n",
    "\n",
    "We have found this with all the respective models\n",
    "\n",
    "|     Metric     | Benchmark Model | Unoptimized Model | Optimized Model |\n",
    "| :------------: | :---------------: | :---------------: | :-------------: | \n",
    "| Accuracy Score | 0.2478           |       0.8701            |      0.8704           |\n",
    "| F-score        | 0.2917          |        0.7497           |   0.7510       |\n",
    "\n",
    "Our next objective is to improve these scores. We are adoting the following two methods\n",
    "\n",
    "- We are doing ```GridSearchCV(...)```with LogisticRegression as the reviewer suggeted to see if we can do some thing better\n",
    "\n",
    "- We shall be using ```XGBoost()``` to see if it still can give the best result as it happens usually\n",
    "\n",
    "We may also perform some **Feature Engineering** with above best model to see if we can boost up the score even further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GridSearchCV on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data.income\n",
    "features = data.drop('income', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8411\n",
      "F-score on testling data: 0.6877\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8432\n",
      "Final F-score on the testing data: 0.6950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "clf = LogisticRegression(class_weight={1: 0.45, 0: 0.56}, \n",
    "                         max_iter=5000,\n",
    "                         solver='newton-cg')\n",
    "\n",
    "params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "grid_obj = GridSearchCV(clf, params, scoring=scorer)\n",
    "grid_fit = grid_obj.fit(X_train, y_train.ravel())\n",
    "predictions = (clf.fit(X_train, y_train.ravel())).predict(X_test)\n",
    "best_clf = grid_fit.best_estimator_\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print \"Unoptimized model\\n------\"\n",
    "print \"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions))\n",
    "print \"F-score on testling data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5))\n",
    "print \"\\nOptimized Model\\n------\"\n",
    "print \"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions))\n",
    "print \"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly both **accuracy** and **f-beta score** is not improved than the Gradient Boosting but it actually imroved than the previous Logistic Regression setup. Lets check for **XGBoost**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
